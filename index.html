<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>RecycleBuddy: Live Classification Demo</title>

    <!-- tailwind for quick, modern styling -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- tensorflow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>

    <style>
        /* simple, clean look */
        body {
            font-family: 'Inter', sans-serif;
        }

        #webcam-container {
            position: relative;
            width: 100%;
            max-width: 500px;
            margin: 0 auto;
            border-radius: 1.5rem;
            overflow: hidden;
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.3);
            aspect-ratio: 4 / 3; /* keep consistent camera frame */
            background-color: #000;
        }

        video,
        canvas {
            display: block;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
    </style>
</head>

<body class="bg-gray-900 min-h-screen p-4 flex flex-col items-center font-sans text-white">
    <div class="w-full max-w-xl text-center">
        <h1 class="text-4xl font-extrabold text-green-400 mt-4 mb-2">RecycleBuddy ‚ôªÔ∏è</h1>
        <p class="text-gray-300 mb-6">
            live ai classification (recyclable vs. non-recyclable)
        </p>
    </div>

    <!-- webcam stream + hidden canvas for resizing frames -->
    <div id="webcam-container">
        <video id="webcam" autoplay playsinline muted></video>
        <canvas id="canvas" class="hidden"></canvas>
    </div>

    <!-- status + result -->
    <div
        id="status-message"
        class="mt-4 p-3 rounded-xl w-full max-w-xl text-center text-lg font-semibold bg-gray-700 text-gray-200 shadow-xl"
    >
        loading model... please wait.
    </div>

    <div
        id="result-display"
        class="mt-4 p-6 text-4xl font-bold rounded-xl w-full max-w-xl shadow-2xl transition duration-500 ease-in-out transform scale-100 bg-gray-800 text-gray-200 text-center"
    >
        <span class="text-xl">Point your camera at the trash item üì∏üöÆ</span>
    </div>

    <div class="w-full max-w-xl text-center mt-6">
        <button
            id="start-button"
            class="px-8 py-4 bg-green-500 text-white text-2xl font-bold rounded-full hover:bg-green-600 focus:outline-none focus:ring-4 focus:ring-green-400 transition duration-150 shadow-lg hidden"
            onclick="startPrediction()"
        >
            start live scan
        </button>
    </div>

    <script>
        // --- config ---
        // put index.html and tfjs_model_artifacts in the same folder.
        const MODEL_URL = 'tfjs_model_artifacts/model.json?v=10';
        const IMAGE_SIZE = 224; // must match your python model
        const LABELS = ['RECYCLABLE ‚ôªÔ∏è', 'NON-RECYCLABLE üóëÔ∏è'];

        // --- globals ---
        let model;
        let webcam;
        let isPredicting = false;

        const statusEl = document.getElementById('status-message');
        const resultEl = document.getElementById('result-display');
        const startButton = document.getElementById('start-button');

        // --- load keras ‚Üí tfjs model ---
        async function loadModel() {
            statusEl.textContent = `loading recyclebuddy model from: ${MODEL_URL}`;
            try {
                console.log('tf.js version:', tf.version);
                console.log('loading model from:', MODEL_URL);

                await tf.ready();
                model = await tf.loadLayersModel(MODEL_URL);

                console.log('model loaded:', model);
                statusEl.textContent = 'model loaded. initializing camera...';
                startButton.classList.remove('hidden');
            } catch (error) {
                console.error('failed to load model:', error);

                statusEl.className =
                    'mt-4 p-3 rounded-xl w-full max-w-xl text-center text-lg font-semibold bg-red-800 text-white shadow-xl';

                // show a more detailed message to help debug
                const msg = error && error.message ? error.message : String(error);
                statusEl.textContent =
                    'error loading model: ' +
                    msg +
                    ' (tip: make sure index.html and tfjs_model_artifacts are in the same folder and you are opening this via http://, not file://)';
            }
        }

        // --- webcam setup ---
        async function setupWebcam() {
            webcam = document.getElementById('webcam');

            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                statusEl.textContent = 'error: camera not supported on this device.';
                return false;
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: false,
                    video: {
                        facingMode: 'environment', // try to use back camera on mobile
                    },
                });

                webcam.srcObject = stream;

                return new Promise((resolve) => {
                    webcam.onloadedmetadata = () => {
                        webcam.play();
                        resolve(true);
                    };
                });
            } catch (error) {
                console.error('error accessing webcam:', error);
                statusEl.textContent = 'camera access denied or failed.';
                return false;
            }
        }

        // --- preprocessing: frame ‚Üí tensor ---
        function preprocess(videoFrame) {
            // tidy helps keep gpu/cpu memory clean between frames
            return tf.tidy(() => {
                let tensor = tf.browser.fromPixels(videoFrame);

                // resize to model input
                const resized = tf.image.resizeBilinear(tensor, [IMAGE_SIZE, IMAGE_SIZE]);

                // normalize 0‚Äì255 ‚Üí 0‚Äì1 (match training)
                const normalized = resized.div(tf.scalar(255.0));

                // add batch dimension: [h, w, c] ‚Üí [1, h, w, c]
                const batched = normalized.expandDims(0);

                return batched;
            });
        }

        // --- main prediction loop ---
        async function predict() {
            if (!isPredicting || !model || !webcam.srcObject) return;

            // schedule the next frame first to keep things smooth
            window.requestAnimationFrame(predict);

            tf.tidy(() => {
                const inputTensor = preprocess(webcam);
                const predictions = model.predict(inputTensor);

                const values = predictions.dataSync();
                const classId = values.indexOf(Math.max(...values));
                const probability = values[classId] * 100;

                const predictionText = `${LABELS[classId]} (${probability.toFixed(0)}%)`;
                resultEl.textContent = predictionText;

                let bgColor, textColor;
                if (classId === 0) {
                    // recyclable
                    bgColor = 'bg-green-600';
                    textColor = 'text-white';
                } else {
                    // non-recyclable
                    bgColor = 'bg-red-600';
                    textColor = 'text-white';
                }

                resultEl.className = `
                    mt-4 p-6 text-4xl font-bold rounded-xl w-full max-w-xl
                    shadow-2xl transition duration-500 ease-in-out transform scale-100
                    text-center ${bgColor} ${textColor}
                `;
            });
        }

        // --- start button handler ---
        async function startPrediction() {
            if (!webcam || !webcam.srcObject) {
                const isReady = await setupWebcam();
                if (!isReady) return;
            }

            if (!model) {
                statusEl.textContent = 'model is still loading. please wait...';
                return;
            }

            statusEl.textContent = 'classification running in real time...';
            isPredicting = true;
            startButton.classList.add('hidden');
            predict();
        }

        // --- page init ---
        window.onload = async () => {
            await loadModel();
            await setupWebcam();

            if (model && webcam && webcam.srcObject) {
                statusEl.textContent = 'ready! tap ‚Äústart live scan‚Äù to begin.';
            }
        };
    </script>
</body>
</html>